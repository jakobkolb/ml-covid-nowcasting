{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from load_data import loading_and_pre_processing_pipeline\n",
    "\n",
    "feature_data = loading_and_pre_processing_pipeline()\n",
    "cleaned_feature_data = feature_data.dropna(axis=0)\n",
    "\n",
    "print(\n",
    "    f'{len(feature_data)} records from {len(set(cleaned_feature_data[\"user_id\"].values))} users present. '\n",
    ")\n",
    "print(f\"{len(cleaned_feature_data)} of which are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = feature_data.dropna(axis=0, subset=[\"test_result\"]).drop(\n",
    "    columns=[\"test_result\", \"user_id\", \"test_week_start\", \"date\"]\n",
    ")\n",
    "y = feature_data.dropna(axis=0, subset=[\"test_result\"])[[\"test_result\"]].astype(bool)\n",
    "\n",
    "classes_count = y.value_counts()\n",
    "classes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As expected, the dataset is heavily imbalanced with a much higher number of negative than positive test results.\n",
    "The problems with this are illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import pandas as pd\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "scoring = [\"accuracy\", \"balanced_accuracy\"]\n",
    "\n",
    "index = []\n",
    "scores = {\"Accuracy\": [], \"Balanced accuracy\": []}\n",
    "\n",
    "# Score a dummy classifier as baseline\n",
    "index += [\"Dummy classifier\"]\n",
    "cv_result = cross_validate(dummy_clf, df, y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "print(f\"Accuracy score of a dummy classifier: {cv_result['test_accuracy'].mean():.3f}\")\n",
    "\n",
    "pd.DataFrame(scores, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This shows that a dummy classifier that classifies all records as the majority class has very high accuracy, simply because it classifies most of the cases correctly. If one corrects for the class imbalance, the accuracy is still 0.5 (random)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "num_pipe = make_pipeline(\n",
    "    StandardScaler(), SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
    ")\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=False),\n",
    "    OrdinalEncoder(),\n",
    ")\n",
    "preprocessor_linear = make_column_transformer(\n",
    "    [num_pipe, selector(dtype_include=\"number\")],\n",
    "    [cat_pipe, selector(dtype_include=\"object\")],\n",
    "    n_jobs=2,\n",
    ")\n",
    "lr_clf = make_pipeline(preprocessor_linear, LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train and score logistic regression\n",
    "index += [\"Logistic regression\"]\n",
    "cv_result = cross_validate(lr_clf, df, y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "pd.DataFrame(scores, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So the accuracy of the logistic regression is essentially the same as a dummy baseline, if it is not corrected for the imbalance of classes in the dataset. Correcting for imbalance, the accuracy is better than chance, but still not very high. There are two things to improve the performance of the model:\n",
    "* First, subsampling the majority class during training to get a balanced training set and\n",
    "* Second, adjusting the loss function of the classifier to weigh cases of the minority class higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_clf.set_params(logisticregression__class_weight=\"balanced\")\n",
    "\n",
    "index += [\"Logistic regression with balanced class weights\"]\n",
    "cv_result = cross_validate(lr_clf, df, y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "pd.DataFrame(scores, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "lr_clf = make_pipeline_with_sampler(\n",
    "    preprocessor_linear,\n",
    "    RandomUnderSampler(random_state=42),\n",
    "    LogisticRegression(max_iter=1000),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index += [\"Under-sampling + Logistic regression\"]\n",
    "cv_result = cross_validate(lr_clf, df, y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "pd.DataFrame(scores, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The performance of both options is comparable and substantially better than the naive regression approach in terms of balanced accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
